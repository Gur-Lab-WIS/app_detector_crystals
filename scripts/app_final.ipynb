{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdd28e-586b-4387-ad71-f39911143649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Standard library imports ----------\n",
    "import os                    # For operating system file and folder handling\n",
    "import sys                   # For system-specific parameters and functions\n",
    "import json                  # For reading and writing JSON files\n",
    "import zipfile              # For working with ZIP archives\n",
    "import tempfile            # For creating temporary files and directories\n",
    "import shutil              # For high-level file operations (copy, move, delete)\n",
    "from io import BytesIO    # For in-memory binary streams\n",
    "from collections import defaultdict  # For dictionary with default values\n",
    "from pathlib import Path    # For modern object-oriented filesystem paths\n",
    "\n",
    "# ---------- Web app framework ----------\n",
    "import streamlit as st       # For creating interactive web applications\n",
    "\n",
    "# ---------- Excel file handling ----------\n",
    "import openpyxl             # For reading and writing Excel files (.xlsx)\n",
    "from xlsxwriter import Workbook  # For creating more advanced Excel files\n",
    "\n",
    "# ---------- Scientific computing ----------\n",
    "import numpy as np          # For numerical computations and arrays\n",
    "import pandas as pd         # For data analysis and table-like data structures\n",
    "import matplotlib           # Core matplotlib configuration\n",
    "import matplotlib.pyplot as plt  # For creating plots and figures\n",
    "matplotlib.use(\"Agg\")       # Use non-interactive backend (safe for headless servers)\n",
    "\n",
    "# ---------- Computer vision and image processing ----------\n",
    "import cv2                  # OpenCV for image processing and computer vision\n",
    "from PIL import Image       # Pillow for general image reading and manipulation\n",
    "\n",
    "# ---------- scikit-image modules ----------\n",
    "from skimage.measure import label, regionprops   # For labeling and region property analysis\n",
    "from skimage.filters import threshold_li         # Li's thresholding\n",
    "from skimage.filters import threshold_otsu       # Otsu's thresholding\n",
    "from skimage.filters import threshold_isodata    # Isodata thresholding\n",
    "from skimage import data, filters, measure, morphology, exposure  # General image functions\n",
    "from skimage.color import rgb2gray               # Convert RGB to grayscale\n",
    "from skimage.morphology import opening, remove_small_objects, remove_small_holes, disk  # Morph operations\n",
    "from skimage import color                         # Additional color space functions\n",
    "from skimage.feature import peak_local_max        # Find local maxima\n",
    "from skimage.segmentation import morphological_chan_vese  # Chan-Vese segmentation\n",
    "from skimage.segmentation import slic             # Superpixel segmentation (SLIC)\n",
    "from skimage.segmentation import active_contour   # Active contour segmentation\n",
    "from skimage.segmentation import watershed        # Watershed segmentation\n",
    "from skimage.io import imread                     # Image reading\n",
    "from skimage.transform import resize              # Image resizing\n",
    "from skimage import draw                          # Drawing shapes on images\n",
    "\n",
    "# ---------- Scientific image processing with SciPy ----------\n",
    "from scipy.ndimage import distance_transform_edt, label as ndi_label  # Distance transforms, labeling\n",
    "from scipy import ndimage           # General n-dimensional image processing functions\n",
    "from scipy.signal import find_peaks  # Find peaks in 1D data\n",
    "import scipy.ndimage as ndi          # Alternative alias for ndimage (duplicate import, but sometimes used for shorter notation)\n",
    "\n",
    "# ---------- Machine learning ----------\n",
    "from sklearn.cluster import KMeans  # K-means clustering for segmentation or grouping\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"Microscopy Image Processing\")\n",
    "\n",
    "# Initialize rerun flag in session_state if not present\n",
    "if \"rerun_flag\" not in st.session_state:\n",
    "    st.session_state.rerun_flag = False\n",
    "\n",
    "# File Upload\n",
    "bf_files = st.file_uploader(\"Upload BF Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "pl_files = st.file_uploader(\"Upload PL Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "\n",
    "# Sort uploaded files\n",
    "if bf_files:\n",
    "    bf_files = sorted(bf_files, key=lambda x: x.name)\n",
    "if pl_files:\n",
    "    pl_files = sorted(pl_files, key=lambda x: x.name)\n",
    "\n",
    "# File Count Info\n",
    "if bf_files and pl_files:\n",
    "    st.success(f\"Found {len(bf_files)} BF files and {len(pl_files)} PL files.\")\n",
    "    if len(bf_files) != len(pl_files):\n",
    "        st.warning(\"The number of BF and PL images does not match. Only matching pairs will be processed.\")\n",
    "\n",
    "    for bf, pl in zip(bf_files, pl_files):\n",
    "        st.write(f\"Processing: {bf.name} and {pl.name}\")\n",
    "\n",
    "# Output Directory\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load scale settings\n",
    "@st.cache_data\n",
    "def load_scale_settings():\n",
    "    try:\n",
    "        with open('scale_map.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {\"20\": 1.29, \"40\": 5.64, \"100\": 13.89, \"200\": 4.78}\n",
    "\n",
    "um_to_px_map = load_scale_settings()\n",
    "\n",
    "# Sidebar Scale Input\n",
    "st.sidebar.header(\"Scale Settings\")\n",
    "selected_um = st.sidebar.selectbox(\"Known Distance (¬µm):\", list(um_to_px_map.keys()))\n",
    "distance_in_px = st.sidebar.text_input(\"Distance in Pixels:\", value=str(um_to_px_map.get(selected_um, \"\")))\n",
    "\n",
    "# Convert to float with error handling\n",
    "try:\n",
    "    s_um = float(selected_um)\n",
    "    d_px = float(distance_in_px)\n",
    "    PIXEL_TO_UM = 1 / (s_um / d_px)\n",
    "    st.success(f\"Calibration result: 1 px = {PIXEL_TO_UM:.4f} ¬µm\")\n",
    "    st.session_state.pixel_to_um = PIXEL_TO_UM\n",
    "except ValueError:\n",
    "    st.error(\"Please enter valid numeric values for scale calibration.\")\n",
    "\n",
    "# Add Scale Section\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.subheader(\"Manage Scale Settings\")\n",
    "\n",
    "new_um = st.sidebar.text_input(\"New ¬µm value\")\n",
    "new_px = st.sidebar.text_input(\"New pixel value\")\n",
    "if st.sidebar.button(\"‚ûï Add Scale\"):\n",
    "    try:\n",
    "        new_um_f = float(new_um)\n",
    "        new_px_f = float(new_px)\n",
    "        um_to_px_map[str(int(new_um_f))] = new_px_f\n",
    "        with open('scale_map.json', 'w') as f:\n",
    "            json.dump(um_to_px_map, f, indent=4)\n",
    "        st.sidebar.success(f\"Added scale: {int(new_um_f)} ¬µm = {new_px_f} px\")\n",
    "        st.cache_data.clear()\n",
    "        # Toggle rerun_flag to trigger rerun\n",
    "        st.session_state.rerun_flag = not st.session_state.rerun_flag\n",
    "    except ValueError:\n",
    "        st.sidebar.error(\"Enter valid numbers to add scale.\")\n",
    "\n",
    "# Delete Scale Option\n",
    "delete_um = st.sidebar.selectbox(\"Select ¬µm to delete\", list(um_to_px_map.keys()))\n",
    "if st.sidebar.button(\"üóëÔ∏è Delete Scale\"):\n",
    "    try:\n",
    "        um_to_px_map.pop(delete_um, None)\n",
    "        with open('scale_map.json', 'w') as f:\n",
    "            json.dump(um_to_px_map, f, indent=4)\n",
    "        st.sidebar.success(f\"Deleted scale: {delete_um} ¬µm\")\n",
    "        st.cache_data.clear()\n",
    "        # Toggle rerun_flag to trigger rerun\n",
    "        st.session_state.rerun_flag = not st.session_state.rerun_flag\n",
    "    except Exception as e:\n",
    "        st.sidebar.error(f\"Error deleting: {e}\")\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script1_done\" not in st.session_state:\n",
    "    st.session_state.script1_done = False\n",
    "if \"script1_results\" not in st.session_state:\n",
    "    st.session_state.script1_results = []\n",
    "if \"zip_path_1\" not in st.session_state:\n",
    "    st.session_state.zip_path_1 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells with crystals\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script1_done = True\n",
    "        st.session_state.script1_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script1_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "    # Placeholder for storing row data to summarize in Excel or logs\n",
    "    summary_rows = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "        \n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "\n",
    "        # ----- CROP SCALE BAR REGION (e.g., bottom-right %) -----\n",
    "        h, w = grayA.shape\n",
    "        crop_margin_h = int(0.015* h)  # % of height-0.01\n",
    "        crop_margin_w = int(0.025 * w)  # % of width-0.02\n",
    "\n",
    "        # Create a mask that excludes bottom-right corner\n",
    "        mask = np.ones_like(grayA, dtype=bool)\n",
    "        mask[h - crop_margin_h:, w - crop_margin_w:] = False\n",
    "        grayA = grayA * mask  # Set scale bar region to 0\n",
    "        \n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(6))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(6))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        #Label connected regions in binary mask\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "    \n",
    "        # Define crop box coordinates (bottom-right crop region)\n",
    "        crop_start_row = h - crop_margin_h\n",
    "        crop_start_col = w - crop_margin_w\n",
    "\n",
    "        filtered_labels = []\n",
    "\n",
    "        # Create a mask for the crop area pixels\n",
    "        crop_mask = np.zeros_like(region_labels_A, dtype=bool)\n",
    "        crop_mask[crop_start_row:, crop_start_col:] = True\n",
    "\n",
    "        for region in region_props_A:\n",
    "            # Get the mask of this region (boolean)\n",
    "            region_mask = (region_labels_A == region.label)\n",
    "    \n",
    "            # Check if any pixel in this region overlaps with the crop mask\n",
    "            if np.any(region_mask & crop_mask):\n",
    "                # Region overlaps the crop area, skip it\n",
    "                continue\n",
    "    \n",
    "            filtered_labels.append(region.label)\n",
    "\n",
    "        # Create new labeled image excluding those regions\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        for lbl in filtered_labels:\n",
    "            new_label_img[region_labels_A == lbl] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "        region_labels_A[crop_start_row:, crop_start_col:] = 0\n",
    "\n",
    "        # Update region_labels_A and region_props_A to filtered versions\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # üî• Reset labels to start from 1\n",
    "        region_labels_A = label(region_labels_A > 0)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "        # Generate a dataframe for cells.\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count()\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "\n",
    "        # Mask bottom-right to remove scale bar artifacts\n",
    "        h2, w2 = overlap.shape\n",
    "        overlap[h2-60:h2, w2-450:w2] = 0\n",
    "        \n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match_cell = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (¬µm¬≤)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ‚úÖ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "\n",
    "        # Generate a dataframe for crystals.\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "\n",
    "        if not df_mapping.empty and \"Region_Area (¬µm¬≤)\" in df_mapping.columns:\n",
    "            df_mapping = df_mapping[(df_mapping[\"Region_Area (¬µm¬≤)\"] < 10) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "            df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "            total_distinct_cells = df_mapping[\"Associated_Cell\"].nunique()\n",
    "            df_mapping[\"Total_Cells_with_crystals\"] = total_distinct_cells\n",
    "            total_area_cr = df_mapping[\"Region_Area (¬µm¬≤)\"].sum()\n",
    "            total_row = [\"\", \"\", \"\", \"Total Area Crystals\", total_area_cr, \"\", \"\"]\n",
    "            df_mapping.loc[\"Total\"] = total_row\n",
    "        else:\n",
    "            total_distinct_cells = 0\n",
    "\n",
    "        # Save cell-to-crystal list (for debugging or export) ---\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                \"Crystal_Labels\": \", \".join(map(str, set(crystals))),  # remove duplicates\n",
    "                \"Crystal_Count\": len(set(crystals))                    # correct count\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "\n",
    "        # Merge only if df_mapping has Associated_Cell\n",
    "        if not df_mapping.empty and \"Associated_Cell\" in df_mapping.columns:\n",
    "            merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "        else:\n",
    "            merged_df = pd.DataFrame()\n",
    "\n",
    "        # Groups all datasets into a single dataset.\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Calculate percentage (formatted as string with 2 decimals and % sign)\n",
    "        percentage = f\"{(total_distinct_cells / total_cells * 100):.2f}%\" if total_cells > 0 else \"0%\"\n",
    "\n",
    "        # Create a summary dataframe (one row for each file)\n",
    "        summary_rows.append({\n",
    "            \"Day\": os.path.splitext(bf_file.name)[0],\n",
    "            \"Total_Cells\": total_cells,\n",
    "            \"Cells_with_Crystals\": total_distinct_cells,\n",
    "            \"%_cells_with_crystals\": percentage\n",
    "        })\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script1_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_image_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    #---------------------------------------------------------------------------------------------------------------------------------------\n",
    "    summary_df[\"Day\"] = summary_df[\"Day\"].astype(str)\n",
    "    summary_df = summary_df.sort_values(by=\"Day\")\n",
    "\n",
    "    # Convert percentage to float\n",
    "    summary_df[\"%_cells_with_crystals\"] = summary_df[\"%_cells_with_crystals\"].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "    # Extract number to group\n",
    "    summary_df[\"DAYS\"] = summary_df[\"Day\"].str.extract(r\"(\\d+)\")\n",
    "\n",
    "    # Group by day\n",
    "    grouped_df = summary_df.groupby(\"DAYS\").agg({\n",
    "        \"%_cells_with_crystals\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "    grouped_df.columns = [\"DAYS\", \"mean_percentage\", \"std_percentage\"]\n",
    "    grouped_df[\"DAYS\"] = grouped_df[\"DAYS\"].astype(int)\n",
    "    grouped_df = grouped_df.sort_values(by=\"DAYS\")\n",
    "    #----------------------------------------------------------------------------------------------------------------------------------------\n",
    "    excel_path_2 = os.path.join(output_dir, \"Plot.xlsx\")\n",
    "    grouped_df.to_excel(excel_path_2, index=False)\n",
    "    #--------------------------------------------\n",
    "    # üìà Save % cells with crystals plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.errorbar(grouped_df[\"DAYS\"], grouped_df[\"mean_percentage\"], yerr=grouped_df[\"std_percentage\"], fmt='o-', color='blue', ecolor='gray', capsize=5)\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    ax.set_ylabel(\"% Cells with Crystals\")\n",
    "    ax.set_title(\"Mean % Cells with Crystals Over Time\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    plot_img_path = os.path.join(output_dir, \"Plot.png\")\n",
    "    fig.savefig(plot_img_path)\n",
    "    all_output_files.append(plot_img_path)\n",
    "    #----------------------------------------------------------------\n",
    "    # Add summary file info to session state separately\n",
    "    st.session_state.script1_results.append({\n",
    "        \"bf_name\": bf_file.name,\n",
    "        \"excel_path\": grouped_xlsx_path,\n",
    "        \"annotated_image_path\": annotated_image_path,\n",
    "        \"overlap_path\": overlap_path,\n",
    "        \"hist_A_path\": hist_path_A,\n",
    "        \"hist_B_path\": hist_path_B,\n",
    "        \"excel_path_2\": excel_path_2\n",
    "    })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_1 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_1, 'w') as zipf_1:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_1.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_1 = zip_path_1\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "if st.session_state.script1_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for idx, result1 in enumerate(st.session_state.script1_results):\n",
    "        st.subheader(f\"üìÅ {result1['bf_name']}\")\n",
    "\n",
    "        if \"annotated_image_path\" in result1 and \"overlap_path\" in result1:\n",
    "            st.image(result1[\"annotated_image_path\"], caption=\"Detections crystals\")\n",
    "            st.image(result1[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        # Only ONE dataset button per image\n",
    "        if \"excel_path\" in result1:\n",
    "            with open(result1[\"excel_path\"], \"rb\") as f1:\n",
    "                st.download_button(\n",
    "                    \"üìä Download Dataset\",\n",
    "                    f1,\n",
    "                    file_name=os.path.basename(result1[\"excel_path\"]),\n",
    "                    key=f\"download_button_{idx}_{os.path.basename(result1['excel_path'])}\"\n",
    "                )\n",
    "\n",
    "    with open(st.session_state.zip_path_1, \"rb\") as zf_1:\n",
    "        st.download_button(\n",
    "            \"üóÇÔ∏è Download All Images and Histograms\",\n",
    "            zf_1,\n",
    "            file_name=\"All_Images_histograms.zip\",\n",
    "            key=f\"download_zip_histograms_{idx}\"\n",
    "        )\n",
    "\n",
    "    if \"excel_path_2\" in result1:\n",
    "        with open(result1[\"excel_path_2\"], \"rb\") as f2:\n",
    "            st.download_button(\n",
    "                \"üìä Download Summary Plot\",\n",
    "                f2,\n",
    "                file_name=os.path.basename(result1[\"excel_path_2\"]),\n",
    "                key=f\"download_summary_button_{idx}\"\n",
    "            )\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script2_done\" not in st.session_state:\n",
    "    st.session_state.script2_done = False\n",
    "if \"script2_results\" not in st.session_state:\n",
    "    st.session_state.script2_results = []\n",
    "if \"zip_path_2\" not in st.session_state:\n",
    "    st.session_state.zip_path_2 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Areas\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script2_done = True\n",
    "        st.session_state.script2_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script2_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "    # Placeholder for storing row data to summarize in Excel or logs\n",
    "    summary_rows = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "        \n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "\n",
    "        # ----- CROP SCALE BAR REGION (e.g., bottom-right %) -----\n",
    "        h, w = grayA.shape\n",
    "        crop_margin_h = int(0.015* h)  # % of height-0.01\n",
    "        crop_margin_w = int(0.025 * w)  # % of width-0.02\n",
    "\n",
    "        # Create a mask that excludes bottom-right corner\n",
    "        mask = np.ones_like(grayA, dtype=bool)\n",
    "        mask[h - crop_margin_h:, w - crop_margin_w:] = False\n",
    "        grayA = grayA * mask  # Set scale bar region to 0\n",
    "        \n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(6))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(6))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        #Label connected regions in binary mask\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "    \n",
    "        # Define crop box coordinates (bottom-right crop region)\n",
    "        crop_start_row = h - crop_margin_h\n",
    "        crop_start_col = w - crop_margin_w\n",
    "\n",
    "        filtered_labels = []\n",
    "\n",
    "        # Create a mask for the crop area pixels\n",
    "        crop_mask = np.zeros_like(region_labels_A, dtype=bool)\n",
    "        crop_mask[crop_start_row:, crop_start_col:] = True\n",
    "\n",
    "        for region in region_props_A:\n",
    "            # Get the mask of this region (boolean)\n",
    "            region_mask = (region_labels_A == region.label)\n",
    "    \n",
    "            # Check if any pixel in this region overlaps with the crop mask\n",
    "            if np.any(region_mask & crop_mask):\n",
    "                # Region overlaps the crop area, skip it\n",
    "                continue\n",
    "    \n",
    "            filtered_labels.append(region.label)\n",
    "\n",
    "        # Create new labeled image excluding those regions\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        for lbl in filtered_labels:\n",
    "            new_label_img[region_labels_A == lbl] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "        region_labels_A[crop_start_row:, crop_start_col:] = 0\n",
    "\n",
    "        # Update region_labels_A and region_props_A to filtered versions\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # üî• Reset labels to start from 1\n",
    "        region_labels_A = label(region_labels_A > 0)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "        #Generate a dataframe for cells\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count()\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "        total_area = region_area_df[\"Region_Area (¬µm¬≤)\"].sum()\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4.6 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "\n",
    "        # Mask bottom-right to remove scale bar artifacts\n",
    "        h2, w2 = overlap.shape\n",
    "        overlap[h2-60:h2, w2-450:w2] = 0\n",
    "        \n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match_cell = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (¬µm¬≤)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ‚úÖ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "                \n",
    "        # Generate a dataframe for crystals.\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "\n",
    "        if not df_mapping.empty and \"Region_Area (¬µm¬≤)\" in df_mapping.columns:\n",
    "            df_mapping = df_mapping[(df_mapping[\"Region_Area (¬µm¬≤)\"] < 6) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "            df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "            total_distinct_cells = df_mapping[\"Associated_Cell\"].nunique()\n",
    "            df_mapping[\"Total_Cells_with_crystals\"] = total_distinct_cells\n",
    "            total_area_cr = df_mapping[\"Region_Area (¬µm¬≤)\"].sum()\n",
    "            total_row = [\"\", \"\", \"\", \"Total Area Crystals\", total_area_cr, \"\", \"\"]\n",
    "            df_mapping.loc[\"Total\"] = total_row\n",
    "        else:\n",
    "            total_distinct_cells = 0\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                \"Crystal_Labels\": \", \".join(map(str, set(crystals))),  # remove duplicates\n",
    "                \"Crystal_Count\": len(set(crystals))                    # correct count\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "        \n",
    "        # Merge only if df_mapping has Associated_Cell\n",
    "        if not df_mapping.empty and \"Associated_Cell\" in df_mapping.columns:\n",
    "            merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "        else:\n",
    "            merged_df = pd.DataFrame()\n",
    "\n",
    "        # Groups all datasets into a single dataset.\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Calculate the percentage of crystal-covered area relative to total cell area\n",
    "        Percentage = f\"{(total_area_cr / total_area * 100):.2f}%\" if total_cells > 0 else \"0%\"\n",
    "\n",
    "        # Create a summary dataframe (one row for each file)\n",
    "        summary_rows.append({\n",
    "                \"Day\": os.path.splitext(bf_file.name)[0],            # Extract image identifier from filename\n",
    "                \"total_cells_area\": total_area,                 # Sum of all cell region areas in ¬µm¬≤\n",
    "                \"total_crystals_area\": total_area_cr,           # Sum of all crystal region areas in ¬µm¬≤\n",
    "                \"%_area_crystals_cells\": Percentage             # Area percentage of crystals relative to cells\n",
    "            })\n",
    "        # Save session result\n",
    "        st.session_state.script2_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_image_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    #---------------------------------------------\n",
    "    summary_df[\"Day\"] = summary_df[\"Day\"].astype(str)\n",
    "    summary_df = summary_df.sort_values(by=\"Day\")\n",
    "\n",
    "    # Convert the percentage to float (if it comes as a string with \"%\")\n",
    "    summary_df[\"%_area_crystals_cells\"] = summary_df[\"%_area_crystals_cells\"].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "    # Extract the number to group (e.g., \"1A\" ‚Üí \"1\")\n",
    "    summary_df[\"DAYS\"] = summary_df[\"Day\"].str.extract(r\"(\\d+)\")  # solo n√∫meros\n",
    "\n",
    "    # Group by group_id and calculate average and standard deviation\n",
    "    grouped_df = summary_df.groupby(\"DAYS\").agg({\n",
    "        \"%_area_crystals_cells\": [\"mean\", \"std\"]\n",
    "    }).reset_index()\n",
    "\n",
    "    # Flatten columns\n",
    "    grouped_df.columns = [\"DAYS\", \"mean_percentage\", \"std_percentage\"]\n",
    "\n",
    "    # Ordenar por group_id como entero\n",
    "    grouped_df[\"DAYS\"] = grouped_df[\"DAYS\"].astype(int)\n",
    "    grouped_df = grouped_df.sort_values(by=\"DAYS\")\n",
    "    #------------------------------------------------------------------\n",
    "    excel_path_2 = os.path.join(output_dir, \"Plot.xlsx\")\n",
    "    grouped_df.to_excel(excel_path_2, index=False)\n",
    "    #-------------------------------\n",
    "    # üìà Save % cells with crystals plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.errorbar(grouped_df[\"DAYS\"], grouped_df[\"mean_percentage\"], yerr=grouped_df[\"std_percentage\"], fmt='o-', color='blue', ecolor='gray', capsize=5)\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    ax.set_ylabel(\"% Area Crystals/Cells\")\n",
    "    ax.set_title(\"Mean % Area Crystals/Cells Over Time\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    plot_img_path = os.path.join(output_dir, \"Plot.png\")\n",
    "    fig.savefig(plot_img_path)\n",
    "    all_output_files.append(plot_img_path)\n",
    "    #---------------------------------------------\n",
    "    # Add summary file info to session state separately\n",
    "    st.session_state.script2_results.append({\n",
    "        \"bf_name\": bf_file.name,\n",
    "        \"excel_path\": grouped_xlsx_path,\n",
    "        \"annotated_image_path\": annotated_image_path,\n",
    "        \"overlap_path\": overlap_path,\n",
    "        \"hist_A_path\": hist_path_A,\n",
    "        \"hist_B_path\": hist_path_B,\n",
    "        \"excel_path_2\": excel_path_2\n",
    "    })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_2 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_2, 'w') as zipf_2:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_2.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_2 = zip_path_2\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "if st.session_state.script2_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for idx, result2 in enumerate(st.session_state.script2_results):\n",
    "        st.subheader(f\"üìÅ {result2['bf_name']}\")\n",
    "\n",
    "        if \"annotated_image_path\" in result2 and \"overlap_path\" in result2:\n",
    "            st.image(result2[\"annotated_image_path\"], caption=\"Detections crystals\")\n",
    "            st.image(result2[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        # Only ONE dataset button per image\n",
    "        if \"excel_path\" in result2:\n",
    "            with open(result2[\"excel_path\"], \"rb\") as f2:\n",
    "                st.download_button(\n",
    "                    \"üìä Download Dataset\",\n",
    "                    f2,\n",
    "                    file_name=os.path.basename(result2[\"excel_path\"]),\n",
    "                    key=f\"download_button_{idx}_{os.path.basename(result2['excel_path'])}\"\n",
    "                )\n",
    "\n",
    "    with open(st.session_state.zip_path_2, \"rb\") as zf_2:\n",
    "        st.download_button(\n",
    "            \"üóÇÔ∏è Download All Images and Histograms\",\n",
    "            zf_2,\n",
    "            file_name=\"All_Images_histograms.zip\",\n",
    "            key=f\"download_zip_histograms_{idx}\"\n",
    "        )\n",
    "\n",
    "    first_result_2 = st.session_state.script2_results[0]\n",
    "    if \"excel_path_2\" in first_result_2:\n",
    "        with open(first_result_2[\"excel_path_2\"], \"rb\") as f3:\n",
    "            st.download_button(\n",
    "                \"üìä Download Summary Plot\",\n",
    "                f3,\n",
    "                file_name=os.path.basename(first_result[\"excel_path_2\"]),\n",
    "                key=\"download_summary_button\"\n",
    "            )\n",
    "\n",
    "    if \"excel_path_2\" in result2:\n",
    "        with open(result2[\"excel_path_2\"], \"rb\") as f3:\n",
    "            st.download_button(\n",
    "                \"üìä Download Summary Plot\",\n",
    "                f3,\n",
    "                file_name=os.path.basename(result2[\"excel_path_2\"]),\n",
    "                key=f\"download_summary_button_{idx}\"\n",
    "            )\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script3_done\" not in st.session_state:\n",
    "    st.session_state.script3_done = False\n",
    "if \"script3_results\" not in st.session_state:\n",
    "    st.session_state.script3_results = []\n",
    "if \"zip_path_3\" not in st.session_state:\n",
    "    st.session_state.zip_path_3 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script3_done = True\n",
    "        st.session_state.script3_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script3_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "\n",
    "        # ----- CROP SCALE BAR REGION (e.g., bottom-right %) -----\n",
    "        h, w = grayA.shape\n",
    "        crop_margin_h = int(0.015* h)  # % of height-0.01\n",
    "        crop_margin_w = int(0.025 * w)  # % of width-0.02\n",
    "\n",
    "        # Create a mask that excludes bottom-right corner\n",
    "        mask = np.ones_like(grayA, dtype=bool)\n",
    "        mask[h - crop_margin_h:, w - crop_margin_w:] = False\n",
    "        grayA = grayA * mask  # Set scale bar region to 0\n",
    "        \n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(6))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(6))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        #Label connected regions in binary mask\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "    \n",
    "        # Define crop box coordinates (bottom-right crop region)\n",
    "        crop_start_row = h - crop_margin_h\n",
    "        crop_start_col = w - crop_margin_w\n",
    "\n",
    "        filtered_labels = []\n",
    "\n",
    "        # Create a mask for the crop area pixels\n",
    "        crop_mask = np.zeros_like(region_labels_A, dtype=bool)\n",
    "        crop_mask[crop_start_row:, crop_start_col:] = True\n",
    "\n",
    "        for region in region_props_A:\n",
    "            # Get the mask of this region (boolean)\n",
    "            region_mask = (region_labels_A == region.label)\n",
    "    \n",
    "            # Check if any pixel in this region overlaps with the crop mask\n",
    "            if np.any(region_mask & crop_mask):\n",
    "                # Region overlaps the crop area, skip it\n",
    "                continue\n",
    "    \n",
    "            filtered_labels.append(region.label)\n",
    "\n",
    "        # Create new labeled image excluding those regions\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        for lbl in filtered_labels:\n",
    "            new_label_img[region_labels_A == lbl] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "        region_labels_A[crop_start_row:, crop_start_col:] = 0\n",
    "\n",
    "        # Update region_labels_A and region_props_A to filtered versions\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # üî• Reset labels to start from 1\n",
    "        region_labels_A = label(region_labels_A > 0)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "        # Generate a dataframe for cells.\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count()\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script3_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"annotated_path\": annotated_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_path_Areas\": hist_path_Areas,\n",
    "            \"excel_path\": excel_path,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_3 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_3, 'w') as zipf_3:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_3.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_3 = zip_path_3\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script3_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for idx, result3 in enumerate(st.session_state.script3_results):\n",
    "        st.subheader(f\"üìÅ {result3['bf_name']}\")\n",
    "        st.image(result3[\"annotated_path\"], caption=\"Segmented Image\")\n",
    "        st.image(result3[\"hist_path_Areas\"], caption=\"Areas Histogram\")\n",
    "        st.image(result3[\"hist_A_path\"], caption=\"Pixels Intensity Histogram\")\n",
    "\n",
    "        with open(result3[\"excel_path\"], \"rb\") as f3:\n",
    "            st.download_button(\"üìä Download Dataset\",f3,file_name=os.path.basename(result3[\"excel_path\"]),key=f\"download_button_{idx}_{os.path.basename(result3['excel_path'])}\")\n",
    "\n",
    "    with open(st.session_state.zip_path_3, \"rb\") as zf_3:\n",
    "        st.download_button(\"üóÇÔ∏è Download All Images and Histograms\", zf_3, file_name=\"All_Images_histograms.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
